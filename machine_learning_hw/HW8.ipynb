{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDVyNZ5cKmsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, GRU, Bidirectional, TimeDistributed, InputLayer, Embedding, Conv1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofQY7M1TL40J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(0)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM5-HpFWRemg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize(model):\n",
        "  plt.plot(model.history.history['accuracy'])\n",
        "  plt.plot(model.history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouEK4i4gTvBg",
        "colab_type": "code",
        "outputId": "0ad65b0f-9640-43cb-c391-a7a832cf087c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('treebank')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CANFryBKT3BG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIFbyNBmT4t3",
        "colab_type": "code",
        "outputId": "3ba93e8d-3281-4f13-c547-d9304c31a71b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "tagged_sentences[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " (',', ','),\n",
              " ('61', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('join', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('board', 'NN'),\n",
              " ('as', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('nonexecutive', 'JJ'),\n",
              " ('director', 'NN'),\n",
              " ('Nov.', 'NNP'),\n",
              " ('29', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u536zvYVT6fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences, sentence_tags =[], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*tagged_sentence)\n",
        "    sentences.append(sentence)\n",
        "    sentence_tags.append(tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1niK6hTmglT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "2a4949f5-7db7-4c45-85d4-6efe2c81bfc6"
      },
      "source": [
        "for w in sentences[345]:\n",
        "  print(w)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The\n",
            "reason\n",
            ":\n",
            "Share\n",
            "prices\n",
            "of\n",
            "many\n",
            "of\n",
            "these\n",
            "funds\n",
            "this\n",
            "year\n",
            "have\n",
            "climbed\n",
            "much\n",
            "more\n",
            "sharply\n",
            "than\n",
            "the\n",
            "foreign\n",
            "stocks\n",
            "0\n",
            "they\n",
            "hold\n",
            "*T*-1\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HWSTHeFURHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_train, sent_test, tag_train, tag_test = train_test_split(sentences, sentence_tags, test_size=0.2, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WntA_ih_UeW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Counter()\n",
        "for sent in sent_train:\n",
        "    sent = [word.lower() for word in sent]\n",
        "    vocab.update(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9AIBeYdUjEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_vocab = {word for word in vocab if vocab[word] > 5}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsUbUpxBUsgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2id = {'PAD':0,'UNK':1}    \n",
        "for i,word in enumerate(filtered_vocab):\n",
        "      word2id[word] = i + 2\n",
        "\n",
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8BOtFwTVoy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag2id = {'PAD':0}  \n",
        "for tags in tag_train:\n",
        "    for tag in tags:\n",
        "      if tag.lower() not in tag2id:\n",
        "        tag2id[tag.lower()] = len(tag2id)\n",
        "\n",
        "id2tag = {i:tag for tag, i in tag2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWzXM7UAVyy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data2ints(data, smth2id):\n",
        "  int_data = []\n",
        "  for seq in data:\n",
        "      int_seq = []\n",
        "      for i in seq:\n",
        "          try:\n",
        "            int_seq.append(smth2id[i.lower()])\n",
        "          except KeyError:\n",
        "            int_seq.append(smth2id['UNK'])\n",
        "  \n",
        "      int_data.append(int_seq)\n",
        "  return int_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXW3yoYIV22S",
        "colab_type": "code",
        "outputId": "6f53ff7b-4f81-4a8a-909b-94f21a8cb148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X_train_ids, X_test_ids = data2ints(sent_train, word2id), data2ints(sent_test, word2id)\n",
        "y_train_ids, y_test_ids = data2ints(tag_train, tag2id), data2ints(tag_test, tag2id)\n",
        "\n",
        "\n",
        "print(X_train_ids[0])\n",
        "print(X_test_ids[0])\n",
        "print(y_train_ids[0])\n",
        "print(y_test_ids[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[409, 1, 1, 1, 1458, 1, 196, 194, 13]\n",
            "[655, 1075, 1678, 197, 504, 2, 380, 1, 1382, 1, 1534, 1512, 519, 13]\n",
            "[1, 1, 1, 2, 1, 1, 3, 4, 5]\n",
            "[18, 19, 21, 24, 10, 25, 24, 18, 21, 14, 3, 7, 15, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByOBD6N3WmVv",
        "colab_type": "code",
        "outputId": "cf88a842-af2a-45ef-fd15-65bb39ba74c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_LEN = max(len(x) for x in sent_train)\n",
        "MAX_LEN"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5puYtEH6WoSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_word, X_test_word = pad_sequences(X_train_ids, maxlen=MAX_LEN, padding='post'), pad_sequences(X_test_ids, maxlen=MAX_LEN, padding='post')\n",
        "y_train_pad, y_test_pad = pad_sequences(y_train_ids, maxlen=MAX_LEN, padding='post'), pad_sequences(y_test_ids, maxlen=MAX_LEN, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXssYVL1WxVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_word, y_test_word = to_categorical(y_train_pad, num_classes=len(tag2id)), to_categorical(y_test_pad, num_classes=len(tag2id))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF2FPZSdz_oL",
        "colab_type": "code",
        "outputId": "2e4f8856-270d-4310-bb16-a10b742af8b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train_word.shape, y_train_word.shape, X_test_word.shape, y_test_word.shape)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3131, 128) (3131, 128, 47) (783, 128) (783, 128, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk6gxZyUkORI",
        "colab_type": "text"
      },
      "source": [
        "# Мое решение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSWJHiWqknGR",
        "colab_type": "text"
      },
      "source": [
        "CharCNN-(bi)LSTM for sequence tagging\n",
        "\n",
        "как мы видим, задача pos-тэггинга плохо решается без морфологической информации . Ваша задача перестроить  нашу сеть так, чтобы она учитывала эту информацию. Постройте сеть, которая имела бы два input слоя:\n",
        "\n",
        "1. один такой же, как мы сделали, подает слова в embedding-слой, а поверх него работает (bi)lstm, проходящая по всей последовательности\n",
        "2. второй входной слой должен брать последовательность слов, каждое из которых представлено буквами (используйте паддинг для добивания каждого слова до максимальной длины слова). Таким образом второй input слой будет принимать массивы размера (batch_size, max_seq_len, max_char_len). Данные с этого input слоя должны попадать в embedding слой (на выходе (batch_size, max_seq_len, max_char_len, char_emb)), затем к ним должна применяться свертка (на выходе (batch_size, max_seq_len, ~max_char_len, kernel_size)), затем расплющивание (на выходе (batch_size, max_seq_len, ~max_char_len*kernel_size)).\n",
        " NB: чтобы слои Conv1D и Flatten возвращали указанные размерности, они должны работать на элементах последовательности, а не на всей последовательности сразу. Для этого вам понадобится обернуть их в TimeDistributed.\n",
        "\n",
        "Полученные выходы с 1. и 2. сконкатенируйте, и пройдитесь по ним (bi)LSTM. В конце, как и в построенной нами сети, испольуйте TimeDistributed Dense слой.\n",
        "\n",
        "Для того, чтобы можно было глазами оценить результат, напишите ф-цию, которая бы брала на вход английское предложение, например любое предложение из теста, и выводила предсказания сети в виде тэгов.\n",
        "\n",
        "Если с построением сети совсем сложно и непонятно, вам должен помочь код вот здесь https://www.depends-on-the-definition.com/lstm-with-char-embeddings-for-ner/  (эмбеддинги символов обрабатываются не свертками, но идея очень похожая)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f91Ag3pTgxn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = set([w_i for sentence in sentences for word in sentence for w_i in word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxlZB0SSnjwx",
        "colab_type": "code",
        "outputId": "e8f1f7c9-e968-4d18-9e51-0a5965c62416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_chars = len(chars)\n",
        "print(n_chars)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_31z9w7qyXD",
        "colab_type": "code",
        "outputId": "0f808957-5cce-4871-b759-c326b86f8f3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_LEN_CHAR = 0\n",
        "for sentence in sentences:\n",
        "  for w in sentence:\n",
        "    if MAX_LEN_CHAR < len(w):\n",
        "      MAX_LEN_CHAR = len(w)\n",
        "MAX_LEN_CHAR"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptH4JEz8rrCi",
        "colab_type": "code",
        "outputId": "5d23b332-9e33-4799-dcd4-887c18383025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_LEN = max(len(x) for x in sent_train)\n",
        "MAX_LEN"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWwhvwEen9fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbws-zXoaPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
        "char2idx[\"UNK\"] = 1\n",
        "char2idx[\"PAD\"] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hzoXENZQqXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def char2ints(data, smth2id):\n",
        "  data_char = []\n",
        "  for sentence in data:\n",
        "    sent_seq = []\n",
        "    for i in range(MAX_LEN):\n",
        "      word_seq = []\n",
        "      for j in range(MAX_LEN_CHAR):\n",
        "        try:\n",
        "          word_seq.append(char2idx.get(sentence[i][0][j]))\n",
        "        except:\n",
        "          word_seq.append(char2idx.get(\"PAD\"))\n",
        "      sent_seq.append(word_seq)\n",
        "    data_char.append(np.array(sent_seq))\n",
        "\n",
        "  return data_char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76SOaEgN2S1r",
        "colab_type": "code",
        "outputId": "7931a2e1-d784-4667-dd8c-28614e5d3505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#тестовая попытка\n",
        "X_train_ids_char, X_test_ids_char = char2ints(sent_train, char2idx), char2ints(sent_test, char2idx)\n",
        "X_train_char, X_test_char = pad_sequences(X_train_ids_char, maxlen=MAX_LEN, padding='post'), pad_sequences(X_test_ids_char, maxlen=MAX_LEN, padding='post')\n",
        "print(X_train_word.shape, y_train_word.shape, X_train_char.shape, X_test_word.shape, y_test_word.shape, X_test_char.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3131, 128) (3131, 128, 47) (3131, 128, 24) (783, 128) (783, 128, 47) (783, 128, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcu26_PnQIKg",
        "colab_type": "code",
        "outputId": "b60390b8-89f0-4515-9b93-dcdac13b9b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_char.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3131, 128, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXqahVDFHoRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_word = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "emb_word = Embedding(input_dim=len(word2id), output_dim=100, mask_zero=True)(input_word)\n",
        "lstm1 = Bidirectional(LSTM(256, return_sequences=True))(emb_word)\n",
        "\n",
        "input_char = tf.keras.layers.Input(shape=(MAX_LEN, MAX_LEN_CHAR,))\n",
        "emb_char = TimeDistributed(Embedding(input_dim=len(char2idx), output_dim=100))(input_char)\n",
        "conv1 = TimeDistributed(Conv1D(kernel_size=12, filters=4, strides=1))(emb_char)\n",
        "flat1 = TimeDistributed(tf.keras.layers.Flatten())(conv1)\n",
        "\n",
        "concat = tf.keras.layers.concatenate([lstm1, flat1])\n",
        "main_lstm = Bidirectional(LSTM(256, return_sequences=True))(concat)\n",
        "dense = TimeDistributed(Dense(len(tag2id), activation=\"sigmoid\"))(main_lstm)\n",
        "\n",
        "model = tf.keras.Model([input_word, input_char], dense)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF8Dsd0F0jep",
        "colab_type": "code",
        "outputId": "f4223a40-b557-4ae2-d151-e1988dd424e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 128, 24)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 128, 24, 100) 8100        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 128, 100)     168100      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 128, 13, 4)   4804        time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 128, 512)     731136      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 128, 52)      0           time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 128, 564)     0           bidirectional[0][0]              \n",
            "                                                                 time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 128, 512)     1681408     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 128, 47)      24111       bidirectional_1[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,617,659\n",
            "Trainable params: 2,617,659\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkMqs9SE1kJy",
        "colab_type": "code",
        "outputId": "da4b8489-c8d6-4e77-a481-549bff3e9425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit([X_train_word, X_train_char], y_train_word, validation_data=([X_test_word, X_test_char], y_test_word), batch_size=64, epochs=10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 277s 6s/step - loss: 0.5994 - accuracy: 0.0423 - val_loss: 0.5923 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 274s 6s/step - loss: 0.5380 - accuracy: 0.0467 - val_loss: 0.4631 - val_accuracy: 0.0788\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 274s 6s/step - loss: 0.3346 - accuracy: 0.1062 - val_loss: 0.2569 - val_accuracy: 0.1307\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 283s 6s/step - loss: 0.1892 - accuracy: 0.1459 - val_loss: 0.1551 - val_accuracy: 0.1636\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 276s 6s/step - loss: 0.1214 - accuracy: 0.1661 - val_loss: 0.1134 - val_accuracy: 0.1747\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 281s 6s/step - loss: 0.0894 - accuracy: 0.1745 - val_loss: 0.0878 - val_accuracy: 0.1804\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 276s 6s/step - loss: 0.0708 - accuracy: 0.1789 - val_loss: 0.0824 - val_accuracy: 0.1823\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 280s 6s/step - loss: 0.0606 - accuracy: 0.1813 - val_loss: 0.0666 - val_accuracy: 0.1860\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 276s 6s/step - loss: 0.0533 - accuracy: 0.1832 - val_loss: 0.0631 - val_accuracy: 0.1867\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 291s 6s/step - loss: 0.0484 - accuracy: 0.1843 - val_loss: 0.0654 - val_accuracy: 0.1859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1067ce10f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0m8J3-2qNS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict([X_test_word ,\n",
        "                        np.array(X_test_char).reshape((len(X_test_char),\n",
        "                                                     MAX_LEN, MAX_LEN_CHAR))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U16ogYSqqz7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "de111671-7d4c-4496-9305-88217784cdc3"
      },
      "source": [
        "i = 1\n",
        "p = np.argmax(y_pred[i], axis=-1)\n",
        "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
        "print(30 * \"=\")\n",
        "for w, t, pred in zip(X_test_word[i], y_test_ids[i], p):\n",
        "    if w != 0:\n",
        "        print(\"{:15}: {:5} {}\".format(id2word[w], id2tag[t], id2tag[pred]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           ||True ||Pred\n",
            "==============================\n",
            "analysts       : nns   nns\n",
            "UNK            : vbp   vbd\n",
            "cray           : nnp   nnp\n",
            "computer       : nnp   nnp\n",
            "'s             : pos   pos\n",
            "UNK            : jj    jj\n",
            "UNK            : nn    vbd\n",
            "value          : nn    nn\n",
            "at             : in    in\n",
            "about          : in    in\n",
            "$              : $     $\n",
            "UNK            : cd    cd\n",
            "*u*            : -none- -none-\n",
            "a              : dt    dt\n",
            "share          : nn    nn\n",
            ".              : .     .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE8wm4fUrRE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = 'Share prices of many of these funds this year have climbed much more sharply than the foreign stocks they hold.'\n",
        "s_ids = data2ints(s, word2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5pi0eZLsKIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_word_pad = pad_sequences(s_ids, maxlen=MAX_LEN, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRSdIPBcs4Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_ids_char = char2ints(s, char2idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tD8nJ7XtTh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "0d4b3c07-a64d-47c9-965b-18adce018062"
      },
      "source": [
        "s_ids_char_pad = pad_sequences(s_ids_char, maxlen=MAX_LEN, padding='post')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-4e6027ebb0a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms_ids_char_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_ids_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m    156\u001b[0m   return sequence.pad_sequences(\n\u001b[1;32m    157\u001b[0m       \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m       padding=padding, truncating=truncating, value=value)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m keras_export(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjKwe9Rgtfmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}