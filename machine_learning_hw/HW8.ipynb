{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDVyNZ5cKmsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, GRU, Bidirectional, TimeDistributed, InputLayer, Embedding, Conv1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofQY7M1TL40J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(0)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM5-HpFWRemg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize(model):\n",
        "  plt.plot(model.history.history['accuracy'])\n",
        "  plt.plot(model.history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouEK4i4gTvBg",
        "colab_type": "code",
        "outputId": "ce131a5d-f2c7-409d-ea4a-4f2a1fc6ccc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('treebank')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CANFryBKT3BG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIFbyNBmT4t3",
        "colab_type": "code",
        "outputId": "4be18210-790f-4dda-c9a3-c03ab73091fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "tagged_sentences[0]\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " (',', ','),\n",
              " ('61', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('join', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('board', 'NN'),\n",
              " ('as', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('nonexecutive', 'JJ'),\n",
              " ('director', 'NN'),\n",
              " ('Nov.', 'NNP'),\n",
              " ('29', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u536zvYVT6fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences, sentence_tags =[], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*tagged_sentence)\n",
        "    sentences.append(sentence)\n",
        "    sentence_tags.append(tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HWSTHeFURHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_train, sent_test, tag_train, tag_test = train_test_split(sentences, sentence_tags, test_size=0.2, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WntA_ih_UeW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Counter()\n",
        "for sent in sent_train:\n",
        "    sent = [word.lower() for word in sent]\n",
        "    vocab.update(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9AIBeYdUjEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_vocab = {word for word in vocab if vocab[word] > 5}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsUbUpxBUsgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2id = {'PAD':0,'UNK':1}    \n",
        "for i,word in enumerate(filtered_vocab):\n",
        "      word2id[word] = i + 2\n",
        "\n",
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8BOtFwTVoy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag2id = {'PAD':0}  \n",
        "for tags in tag_train:\n",
        "    for tag in tags:\n",
        "      if tag.lower() not in tag2id:\n",
        "        tag2id[tag.lower()] = len(tag2id)\n",
        "\n",
        "id2tag = {i:tag for tag, i in tag2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWzXM7UAVyy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data2ints(data, smth2id):\n",
        "  int_data = []\n",
        "  for seq in data:\n",
        "      int_seq = []\n",
        "      for i in seq:\n",
        "          try:\n",
        "            int_seq.append(smth2id[i.lower()])\n",
        "          except KeyError:\n",
        "            int_seq.append(smth2id['UNK'])\n",
        "  \n",
        "      int_data.append(int_seq)\n",
        "  return int_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXW3yoYIV22S",
        "colab_type": "code",
        "outputId": "6c779a5b-d407-4933-cc41-864354fd12d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X_train_ids, X_test_ids = data2ints(sent_train, word2id), data2ints(sent_test, word2id)\n",
        "y_train_ids, y_test_ids = data2ints(tag_train, tag2id), data2ints(tag_test, tag2id)\n",
        "\n",
        "\n",
        "print(X_train_ids[0])\n",
        "print(X_test_ids[0])\n",
        "print(y_train_ids[0])\n",
        "print(y_test_ids[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1658, 1, 1, 1, 577, 1, 1517, 142, 1295]\n",
            "[165, 849, 518, 1405, 480, 144, 604, 1, 1171, 1, 1663, 309, 1518, 1295]\n",
            "[1, 1, 1, 2, 1, 1, 3, 4, 5]\n",
            "[18, 19, 21, 24, 10, 25, 24, 18, 21, 14, 3, 7, 15, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByOBD6N3WmVv",
        "colab_type": "code",
        "outputId": "5faa2193-6598-4f9f-fd64-fb2f5857799f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_LEN = max(len(x) for x in sent_train)\n",
        "MAX_LEN"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5puYtEH6WoSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_word, X_test_word = pad_sequences(X_train_ids, maxlen=MAX_LEN, padding='post'), pad_sequences(X_test_ids, maxlen=MAX_LEN, padding='post')\n",
        "y_train_pad, y_test_pad = pad_sequences(y_train_ids, maxlen=MAX_LEN, padding='post'), pad_sequences(y_test_ids, maxlen=MAX_LEN, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXssYVL1WxVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_word, y_test_word = to_categorical(y_train_pad, num_classes=len(tag2id)), to_categorical(y_test_pad, num_classes=len(tag2id))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF2FPZSdz_oL",
        "colab_type": "code",
        "outputId": "31ea602d-8f33-41e1-e316-7d8190f08279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train_word.shape, y_train_word.shape, X_test_word.shape, y_test_word.shape)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3131, 128) (3131, 128, 47) (783, 128) (783, 128, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk6gxZyUkORI",
        "colab_type": "text"
      },
      "source": [
        "# Мое решение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSWJHiWqknGR",
        "colab_type": "text"
      },
      "source": [
        "CharCNN-(bi)LSTM for sequence tagging\n",
        "\n",
        "как мы видим, задача pos-тэггинга плохо решается без морфологической информации . Ваша задача перестроить  нашу сеть так, чтобы она учитывала эту информацию. Постройте сеть, которая имела бы два input слоя:\n",
        "\n",
        "1. один такой же, как мы сделали, подает слова в embedding-слой, а поверх него работает (bi)lstm, проходящая по всей последовательности\n",
        "2. второй входной слой должен брать последовательность слов, каждое из которых представлено буквами (используйте паддинг для добивания каждого слова до максимальной длины слова). Таким образом второй input слой будет принимать массивы размера (batch_size, max_seq_len, max_char_len). Данные с этого input слоя должны попадать в embedding слой (на выходе (batch_size, max_seq_len, max_char_len, char_emb)), затем к ним должна применяться свертка (на выходе (batch_size, max_seq_len, ~max_char_len, kernel_size)), затем расплющивание (на выходе (batch_size, max_seq_len, ~max_char_len*kernel_size)).\n",
        " NB: чтобы слои Conv1D и Flatten возвращали указанные размерности, они должны работать на элементах последовательности, а не на всей последовательности сразу. Для этого вам понадобится обернуть их в TimeDistributed.\n",
        "\n",
        "Полученные выходы с 1. и 2. сконкатенируйте, и пройдитесь по ним (bi)LSTM. В конце, как и в построенной нами сети, испольуйте TimeDistributed Dense слой.\n",
        "\n",
        "Для того, чтобы можно было глазами оценить результат, напишите ф-цию, которая бы брала на вход английское предложение, например любое предложение из теста, и выводила предсказания сети в виде тэгов.\n",
        "\n",
        "Если с построением сети совсем сложно и непонятно, вам должен помочь код вот здесь https://www.depends-on-the-definition.com/lstm-with-char-embeddings-for-ner/  (эмбеддинги символов обрабатываются не свертками, но идея очень похожая)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f91Ag3pTgxn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = set([w_i for sentence in sentences for word in sentence for w_i in word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxlZB0SSnjwx",
        "colab_type": "code",
        "outputId": "4bb86acf-847f-4c06-d333-71bc3407ee0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_chars = len(chars)\n",
        "print(n_chars)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_31z9w7qyXD",
        "colab_type": "code",
        "outputId": "6ca915f7-625f-481a-d215-d0a160700634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_LEN_CHAR = 0\n",
        "for sentence in sentences:\n",
        "  for w in sentence:\n",
        "    if MAX_LEN_CHAR < len(w):\n",
        "      MAX_LEN_CHAR = len(w)\n",
        "MAX_LEN_CHAR"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptH4JEz8rrCi",
        "colab_type": "code",
        "outputId": "c4156ce4-f382-450c-de47-b48436b7c6ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_LEN = max(len(x) for x in sent_train)\n",
        "MAX_LEN"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWwhvwEen9fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbws-zXoaPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
        "char2idx[\"UNK\"] = 1\n",
        "char2idx[\"PAD\"] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSKh12Nn01ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def char2ints(data, char2idx):\n",
        "  X_char = []\n",
        "  for sentence in sentences:\n",
        "      sent_seq = []\n",
        "      for i in range(MAX_LEN):\n",
        "          word_seq = []\n",
        "          for j in range(MAX_LEN_CHAR):\n",
        "              try:\n",
        "                  word_seq.append(char2idx.get(sentence[i][0][j]))\n",
        "              except:\n",
        "                  word_seq.append(char2idx.get(\"PAD\"))\n",
        "          sent_seq.append(word_seq)\n",
        "      X_char.append(np.array(sent_seq))\n",
        "      \n",
        "  return X_char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4cpTbqR1ZVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_ids_char, X_test_ids_char = char2ints(sent_train, char2idx), char2ints(sent_test, char2idx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0kHK5v52ELr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_ids_char, y_test_ids_char = data2ints(tag_train, tag2id), data2ints(tag_test, tag2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSZ4sCzu2JIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_char, X_test_char = pad_sequences(X_train_ids_char, maxlen=MAX_LEN, padding='post'), pad_sequences(X_test_ids_char, maxlen=MAX_LEN, padding='post')\n",
        "y_train_pad, y_test_pad = pad_sequences(y_train_ids_char, maxlen=MAX_LEN, padding='post'), pad_sequences(y_test_ids_char, maxlen=MAX_LEN, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLWo113MztnN",
        "colab_type": "code",
        "outputId": "b37070f2-d756-4a43-c4d0-f210ff8ed40b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train_word.shape, y_train_word.shape, X_test_word.shape, y_test_word.shape, X_train_char.shape, X_test_char.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3131, 128) (3131, 128, 47) (783, 128) (783, 128, 47) (3914, 128, 24) (3914, 128, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXqahVDFHoRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_word = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "emb_word = Embedding(input_dim=len(word2id), output_dim=100, mask_zero=True)(input_word)\n",
        "lstm1 = Bidirectional(LSTM(256, return_sequences=True))(emb_word)\n",
        "\n",
        "input_char = tf.keras.layers.Input(shape=(MAX_LEN, MAX_LEN_CHAR,))\n",
        "emb_char = TimeDistributed(Embedding(input_dim=len(char2idx), output_dim=50))(input_char)\n",
        "conv1 = TimeDistributed(Conv1D(kernel_size=12, filters=4, strides=1))(emb_char)\n",
        "flat1 = TimeDistributed(tf.keras.layers.Flatten())(conv1)\n",
        "\n",
        "concat = tf.keras.layers.concatenate([lstm1, flat1])\n",
        "main_lstm = Bidirectional(LSTM(256, return_sequences=True))(concat)\n",
        "dense = TimeDistributed(Dense(len(tag2id), activation=\"sigmoid\"))(main_lstm)\n",
        "\n",
        "model = tf.keras.Model([input_word, input_char], dense)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF8Dsd0F0jep",
        "colab_type": "code",
        "outputId": "3389a0b0-bf13-478c-b021-290c72ab0c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 128, 24)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 128, 24, 50)  4050        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 128, 100)     168100      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 128, 13, 4)   2404        time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 128, 512)     731136      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 128, 52)      0           time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 128, 564)     0           bidirectional[0][0]              \n",
            "                                                                 time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 128, 512)     1681408     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 128, 47)      24111       bidirectional_1[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,611,209\n",
            "Trainable params: 2,611,209\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95x0zGrlusz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b2ced231-d25d-420d-92a4-042f03fbb1e8"
      },
      "source": [
        "model.fit(X_train_char, X_train_word, y_train_word, validation_data=(X_test_char, X_test_word, y_test_word), batch_size=128, epochs=10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-70154b415693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit() got multiple values for argument 'batch_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkMqs9SE1kJy",
        "colab_type": "code",
        "outputId": "28f0278a-484d-4244-d329-02cde7ebc77b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "model.fit([X_train_char, X_train_word], y_train_word, validation_data=([X_test_char, X_test_word], y_test_word), batch_size=128, epochs=10)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-b18e02aebc04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    813\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3914, 3131\n  y sizes: 3131\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhpZdAcPvNd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "50687044-4497-4a61-db16-f8e254ed3ea4"
      },
      "source": [
        "model.fit([X_train_word, X_train_char], y_train_word, validation_data=([X_test_word, X_test_char], y_test_word), batch_size=128, epochs=10)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f9f0f50f6e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_char\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_char\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    813\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3131, 3914\n  y sizes: 3131\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lmcfKflvZV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}