{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3_updated.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU4jonmT2r4E",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Задание 1\n",
        "Возьмите четыре любые темы из корпуса 20newsgroups (постарайтесть брать не слишком похожие, и не слишком разные темы). Векторизуйте датасет с помощью CountVectorizer. Выберете три любых классификатора. Используя кроссвалидацию (любой вариант из KFold, StratifiedKFold, RepeatedStratifiedKFold), подберите оптимальные параметры моделей с помощью grid_search. Обучите классификаторы с оптимальными параметрами. Оцените полученные классификаторы на тесте, мера качества - macro_f1. Посмотрите, насколько полученные результаты на тесте отличаются от результатов предсказания на трейне? - 3 балла"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixfE0wPb1-Wv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "5e7a75da-4432-42c7-8100-69cf87ae12d9"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYEjCgITbV4V",
        "colab_type": "code",
        "outputId": "13e480f8-2c25-49e5-d83b-60186393e2c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVx5Qj5J2qlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "import warnings\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-_xNigh2waC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cats = ['sci.electronics', 'sci.med', 'sci.space', 'sci.crypt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Ck3K6Y2x6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=cats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-76MqcOL2ze8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vect = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mx5o7Qr23iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors_train = count_vect.fit_transform(newsgroups_train.data)\n",
        "vectors_test = count_vect.transform(newsgroups_test.data) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAmXANN427vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold = 10\n",
        "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
        "stratified_folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
        "repeated_folds = RepeatedStratifiedKFold(n_splits=n_fold, n_repeats=20, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxLdDm9HQuu6",
        "colab_type": "text"
      },
      "source": [
        "###RidgeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgb1UE9p9mGy",
        "colab_type": "code",
        "outputId": "29fcc2be-bc68-4c31-da1f-d4f7744dac79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "%%time \n",
        "rclf = RidgeClassifier()\n",
        "\n",
        "parameter_grid = {'alpha': [0.001, 0.1, 1, 2, 10]}\n",
        "\n",
        "grid_search = GridSearchCV(rclf, param_grid=parameter_grid, cv=folds, n_jobs=-1)\n",
        "grid_search.fit(vectors_train, newsgroups_train.target)\n",
        "print('Best score: {}'.format(grid_search.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search.best_params_))\n",
        "rlcf = RidgeClassifier(**grid_search.best_params_)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.9351256958479593\n",
            "Best parameters: {'alpha': 10}\n",
            "CPU times: user 3.92 s, sys: 2.78 s, total: 6.7 s\n",
            "Wall time: 2min 30s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydYiVuPjFXWE",
        "colab_type": "code",
        "outputId": "5d6d8ac2-1180-489c-b301-012de09e5370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model1 = rclf.fit(vectors_train, newsgroups_train.target)\n",
        "train_preds1 = model1.predict(vectors_train)\n",
        "test_preds1 = model1.predict(vectors_test)\n",
        "print('result on train: {}'.format(f1_score(newsgroups_train.target, train_preds1, average='macro')))\n",
        "print('result on test: {}'.format(f1_score(newsgroups_test.target,test_preds1, average='macro')))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result on train: 1.0\n",
            "result on test: 0.8244203816916094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLkb8dAKQ26H",
        "colab_type": "text"
      },
      "source": [
        "### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roY9ZE5MDZPl",
        "colab_type": "code",
        "outputId": "910e1f4e-ec45-4456-9691-778bed6f231e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "%%time \n",
        "lr = LogisticRegression()\n",
        "\n",
        "parameter_grid = {'class_weight' : ['balanced', None],\n",
        "                  'penalty' : ['l2', 'l1'],\n",
        "                  'solver' : ['liblinear', 'saga'],\n",
        "                  'C' : [0.001, 0.01, 0.08, 0.1, 0.15, 1.0],\n",
        "                  'max_iter': [2,10,20]\n",
        "                 }\n",
        "\n",
        "grid_search2 = GridSearchCV(lr, param_grid=parameter_grid, cv=folds, n_jobs=-1)\n",
        "grid_search2.fit(vectors_train, newsgroups_train.target)\n",
        "print('Best score: {}'.format(grid_search2.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search2.best_params_))\n",
        "lr = LogisticRegression(**grid_search2.best_params_)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.9561872850405985\n",
            "Best parameters: {'C': 1.0, 'class_weight': None, 'max_iter': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "CPU times: user 6.45 s, sys: 1.4 s, total: 7.84 s\n",
            "Wall time: 11min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPGrg9pyDbez",
        "colab_type": "code",
        "outputId": "17e3f5fc-70fb-4f11-ff96-eb06891e84ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model2 = lr.fit(vectors_train, newsgroups_train.target)\n",
        "train_preds2 = model2.predict(vectors_train)\n",
        "test_preds2 = model2.predict(vectors_test)\n",
        "print('result on train: {}'.format(f1_score(newsgroups_train.target, train_preds2, average='macro')))\n",
        "print('result on test: {}'.format(f1_score(newsgroups_test.target,test_preds2, average='macro')))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result on train: 1.0\n",
            "result on test: 0.9042118694156432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw_XRLFQRVZb",
        "colab_type": "text"
      },
      "source": [
        "### SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyvnBR7yRV1x",
        "colab_type": "code",
        "outputId": "fca74124-0c39-437d-c289-f515c3996629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "%%time\n",
        "sgd = SGDClassifier()\n",
        "\n",
        "parameter_grid = {'penalty': ['l2', 'l1'], \n",
        "                  'alpha': [0.0001, 0.001, 0.01, 0.1], \n",
        "                  'max_iter': [1000, 500, 100]}\n",
        "\n",
        "grid_search3 = GridSearchCV(sgd, param_grid=parameter_grid, cv=folds, n_jobs=-1)\n",
        "grid_search3.fit(vectors_train, newsgroups_train.target)\n",
        "print('Best score: {}'.format(grid_search3.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search3.best_params_))\n",
        "sgd = SGDClassifier(**grid_search3.best_params_)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.9574477892422791\n",
            "Best parameters: {'alpha': 0.01, 'max_iter': 100, 'penalty': 'l2'}\n",
            "CPU times: user 942 ms, sys: 151 ms, total: 1.09 s\n",
            "Wall time: 4min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8ZB3N8iFBYe",
        "colab_type": "code",
        "outputId": "75101780-730f-4d8d-e141-2f7b42f41223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model3 = sgd.fit(vectors_train, newsgroups_train.target)\n",
        "train_preds3 = model3.predict(vectors_train)\n",
        "test_preds3 = model3.predict(vectors_test)\n",
        "print('result on train: {}'.format(f1_score(newsgroups_train.target, train_preds3, average='macro')))\n",
        "print('result on test: {}'.format(f1_score(newsgroups_test.target,test_preds3, average='macro')))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result on train: 1.0\n",
            "result on test: 0.9032315557065068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBl5zPwg56UU",
        "colab_type": "text"
      },
      "source": [
        "### Задание 2\n",
        "Постройте функцию analyze_features(model, n), которая бы для каждой модели выводила самые значимые признаки по каждому из четырех классов. Для этого вам понадобится словарь, связывающий номер признака с самим признаком, он может быть таким: index_to_word = {v:k for k,v in count_vect.vocabulary_.items()} обращаться к весам модели можно либо через eli5, как мы делали на лекции, либо напрямую: через clf.coef_ - матрица размера (n_classes, n_features), то есть для получения признаков с наибольшим весом для класса n вам нужно сортировать веса внутри n-ной строки. если вы используете деревья решений, то можно воспользоваться методом model.feature_importances - 4 балла"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbU8WxKyWZ7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_features(model, n):\n",
        "  index_to_word = {v:k for k,v in count_vect.vocabulary_.items()}\n",
        "  df = eli5.formatters.as_dataframe.explain_weights_df(model)\n",
        "  \n",
        "  class1 = df[df['target']==0]\n",
        "  class2 = df[df['target']==1]\n",
        "  class3 = df[df['target']==2]\n",
        "  class4 = df[df['target']==3]\n",
        "  \n",
        "  print(n, 'самых значимых признаков класса 1 (crypt):')\n",
        "  for element in class1.feature[:n]:\n",
        "    feature = element.strip('x')\n",
        "    print(index_to_word[int(feature)])\n",
        "  \n",
        "  print('\\n', n, 'самых значимых признаков класса 2 (electronics):')\n",
        "  for element in class2.feature[:n]:\n",
        "    feature = element.strip('x')\n",
        "    print(index_to_word[int(feature)])\n",
        "\n",
        "  print('\\n', n, 'самых значимых признаков класса 3 (med):')\n",
        "  for element in class3.feature[:n]:\n",
        "    feature = element.strip('x')\n",
        "    print(index_to_word[int(feature)])\n",
        "\n",
        "  print('\\n', n, 'самых значимых признаков класса 4 (space):')\n",
        "  for element in class4.feature[:n]:\n",
        "    feature = element.strip('x')\n",
        "    print(index_to_word[int(feature)])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hOOQR89cAqA",
        "colab_type": "text"
      },
      "source": [
        "### Задание 3 \n",
        "Примените функцию к вашим классификаторам, видны ли по отобранным словам очевидные ошибки? Используйте параметры CountVectorizer, для того, чтобы уменьшить количество признаков и убрать нерелевантные (например числа, токены слишком низкой или высокой документной частотой, и т.д.), постарайтесь добиться улучшения результатов работы моделей (снова выводите результаты модели на трейне и на тесте, чтобы видеть, уменьшается ли переобучение) - 3 балла"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBGbm-DkYZgv",
        "colab_type": "code",
        "outputId": "3e28429f-7640-441e-f9c1-e3b5f2c9dcd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "analyze_features(model1, 10)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 самых значимых признаков класса 1 (crypt):\n",
            "tapped\n",
            "brinich\n",
            "gtoal\n",
            "clipper\n",
            "dos\n",
            "code\n",
            "issa\n",
            "conference\n",
            "ebcdic\n",
            "pollux\n",
            "\n",
            " 10 самых значимых признаков класса 2 (electronics):\n",
            "motorola\n",
            "yxy4145\n",
            "wayne\n",
            "exploding\n",
            "cars\n",
            "rf\n",
            "grace\n",
            "wex\n",
            "differential\n",
            "intel\n",
            "\n",
            " 10 самых значимых признаков класса 3 (med):\n",
            "photography\n",
            "roxonal\n",
            "radford\n",
            "jmetz\n",
            "jeeves\n",
            "doctor\n",
            "barbecued\n",
            "amniocentesis\n",
            "claussen\n",
            "krillean\n",
            "\n",
            " 10 самых значимых признаков класса 4 (space):\n",
            "planets\n",
            "ryukoku\n",
            "prb\n",
            "shread\n",
            "twist\n",
            "dgi\n",
            "jennise\n",
            "russian\n",
            "race\n",
            "divine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1lrcoGMcAAh",
        "colab_type": "code",
        "outputId": "665c0b6c-8530-4187-ce46-a4d8ac3549ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "analyze_features(model2, 10)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 самых значимых признаков класса 1 (crypt):\n",
            "clipper\n",
            "encryption\n",
            "key\n",
            "code\n",
            "security\n",
            "gtoal\n",
            "pgp\n",
            "chip\n",
            "dos\n",
            "nsa\n",
            "\n",
            " 10 самых значимых признаков класса 2 (electronics):\n",
            "power\n",
            "electronics\n",
            "circuit\n",
            "radar\n",
            "tv\n",
            "motorola\n",
            "out\n",
            "line\n",
            "usa\n",
            "used\n",
            "\n",
            " 10 самых значимых признаков класса 3 (med):\n",
            "doctor\n",
            "msg\n",
            "pitt\n",
            "disease\n",
            "medical\n",
            "information\n",
            "photography\n",
            "treatment\n",
            "health\n",
            "cancer\n",
            "\n",
            " 10 самых значимых признаков класса 4 (space):\n",
            "space\n",
            "orbit\n",
            "moon\n",
            "launch\n",
            "planets\n",
            "dc\n",
            "earth\n",
            "rockets\n",
            "jennise\n",
            "dgi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPGav20ocSp-",
        "colab_type": "code",
        "outputId": "30565b49-ea68-4e78-a4b2-79d9a841028f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "analyze_features(model3, 10)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 самых значимых признаков класса 1 (crypt):\n",
            "db\n",
            "clipper\n",
            "encryption\n",
            "anonymous\n",
            "mov\n",
            "key\n",
            "bh\n",
            "government\n",
            "security\n",
            "code\n",
            "\n",
            " 10 самых значимых признаков класса 2 (electronics):\n",
            "wire\n",
            "circuit\n",
            "wiring\n",
            "power\n",
            "ground\n",
            "used\n",
            "electronics\n",
            "tv\n",
            "neutral\n",
            "use\n",
            "\n",
            " 10 самых значимых признаков класса 3 (med):\n",
            "doctor\n",
            "disease\n",
            "health\n",
            "medical\n",
            "keyboard\n",
            "msg\n",
            "pitt\n",
            "patients\n",
            "treatment\n",
            "cancer\n",
            "\n",
            " 10 самых значимых признаков класса 4 (space):\n",
            "space\n",
            "orbit\n",
            "moon\n",
            "earth\n",
            "launch\n",
            "solar\n",
            "satellite\n",
            "flight\n",
            "shuttle\n",
            "telescope\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdkCvlhE1JEK",
        "colab_type": "text"
      },
      "source": [
        "Очевидных ошибок нет. Если выводить топ10 слов, то все они достаточно информативны и хорошо отражают суть своей категории."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3TKrbbEfBWB",
        "colab_type": "text"
      },
      "source": [
        "### Новый count_vect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5gdStYsYjDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = stopwords.words('english') + list(punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMZDM538cUD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vect_new = CountVectorizer(max_features=1000, min_df=0.01, max_df=0.4, stop_words=noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aISUGv1aUQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors_train_new = count_vect_new.fit_transform(newsgroups_train.data)\n",
        "vectors_test_new = count_vect_new.transform(newsgroups_test.data) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xbEvYZmdvn4",
        "colab_type": "text"
      },
      "source": [
        "Измененный RidgeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUBXsekOb95s",
        "colab_type": "code",
        "outputId": "8699d3d8-b9f9-43ef-cc63-057af638deb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "rclf = RidgeClassifier()\n",
        "\n",
        "parameter_grid = {'alpha': [0.001, 0.1, 1, 2, 10]}\n",
        "\n",
        "grid_search = GridSearchCV(rclf, param_grid=parameter_grid, cv=folds, n_jobs=-1)\n",
        "grid_search.fit(vectors_train_new, newsgroups_train.target)\n",
        "print('Best score: {}'.format(grid_search.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search.best_params_))\n",
        "rlcf = RidgeClassifier(**grid_search.best_params_)\n",
        "\n",
        "model1_new = rclf.fit(vectors_train_new, newsgroups_train.target)\n",
        "train_preds1_new = model1_new.predict(vectors_train_new)\n",
        "test_preds1_new = model1_new.predict(vectors_test_new)\n",
        "print('result on train: {}'.format(f1_score(newsgroups_train.target, train_preds1_new, average='macro')))\n",
        "print('result on test: {}'.format(f1_score(newsgroups_test.target,test_preds1_new, average='macro')))"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.8356469169946459\n",
            "Best parameters: {'alpha': 10}\n",
            "result on train: 0.9764294635741017\n",
            "result on test: 0.6782359923989176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQX6FWOIdzKo",
        "colab_type": "text"
      },
      "source": [
        "Измененная LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJB5mTobd-Zi",
        "colab_type": "code",
        "outputId": "9daf8b51-1d79-47d5-d421-14c59f49f4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "%%time \n",
        "lr = LogisticRegression()\n",
        "\n",
        "parameter_grid = {'class_weight' : ['balanced', None],\n",
        "                  'penalty' : ['l2', 'l1'],\n",
        "                  'solver' : ['liblinear', 'saga'],\n",
        "                  'C' : [0.001, 0.01, 0.08, 0.1, 0.15, 1.0],\n",
        "                  'max_iter': [2,10,20]\n",
        "                 }\n",
        "\n",
        "grid_search2 = GridSearchCV(lr, param_grid=parameter_grid, cv=folds, n_jobs=-1)\n",
        "grid_search2.fit(vectors_train_new, newsgroups_train.target)\n",
        "print('Best score: {}'.format(grid_search2.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search2.best_params_))\n",
        "lr = LogisticRegression(**grid_search2.best_params_)\n",
        "\n",
        "model2_new = lr.fit(vectors_train_new, newsgroups_train.target)\n",
        "train_preds2_new = model2_new.predict(vectors_train_new)\n",
        "test_preds2_new = model2_new.predict(vectors_test_new)\n",
        "print('result on train: {}'.format(f1_score(newsgroups_train.target, train_preds2_new, average='macro')))\n",
        "print('result on test: {}'.format(f1_score(newsgroups_test.target,test_preds2_new, average='macro')))\n",
        "\n"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.9334148849413182\n",
            "Best parameters: {'C': 1.0, 'class_weight': 'balanced', 'max_iter': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "result on train: 1.0\n",
            "result on test: 0.8633568147882489\n",
            "CPU times: user 4.35 s, sys: 416 ms, total: 4.76 s\n",
            "Wall time: 2min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E71-e1rTdzUD",
        "colab_type": "text"
      },
      "source": [
        "Измененный SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V74ebpxNd-79",
        "colab_type": "code",
        "outputId": "85231852-c3a0-494e-e057-eadcf94c12f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "%%time\n",
        "sgd = SGDClassifier()\n",
        "\n",
        "parameter_grid = {'penalty': ['l2', 'l1'], \n",
        "                  'alpha': [0.0001, 0.001, 0.01, 0.1], \n",
        "                  'max_iter': [1000, 500, 100]}\n",
        "\n",
        "grid_search3 = GridSearchCV(sgd, param_grid=parameter_grid, cv=folds, n_jobs=-1)\n",
        "grid_search3.fit(vectors_train_new, newsgroups_train.target)\n",
        "print('Best score: {}'.format(grid_search3.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search3.best_params_))\n",
        "sgd = SGDClassifier(**grid_search3.best_params_)\n",
        "\n",
        "model3_new = sgd.fit(vectors_train_new, newsgroups_train.target)\n",
        "train_preds3_new = model3_new.predict(vectors_train_new)\n",
        "test_preds3_new = model3_new.predict(vectors_test_new)\n",
        "print('result on train: {}'.format(f1_score(newsgroups_train.target, train_preds3_new, average='macro')))\n",
        "print('result on test: {}'.format(f1_score(newsgroups_test.target,test_preds3_new, average='macro')))\n",
        "\n"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.9342658582420309\n",
            "Best parameters: {'alpha': 0.01, 'max_iter': 1000, 'penalty': 'l2'}\n",
            "result on train: 0.9899092922247694\n",
            "result on test: 0.8618318945019036\n",
            "CPU times: user 1.16 s, sys: 122 ms, total: 1.29 s\n",
            "Wall time: 30.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX9yf26h2APR",
        "colab_type": "text"
      },
      "source": [
        "После изменения параметров Countvectorizer переобучение на трейне уменьшилось. Также немного ухудшился результат на тесте. "
      ]
    }
  ]
}