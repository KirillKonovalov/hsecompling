{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5EAZXH0TuK0C+Cmey3XBR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYTDLDB3DqQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "55b24827-4edc-4c8a-a05e-816e4760047d"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.15.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUj5MOh6RuVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fa3c80f3-0503-4347-841b-70957ef5910b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aZd2C5NqbCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from sklearn.ensemble import VotingClassifier \n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.svm import SVC \n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4_mRAqZvya9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29fe32ef-5805-4867-8131-3e1e7726bae3"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy0f5R_GxBFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/gdrive/My Drive/exam/jigsaw-toxic-comment-train.csv.zip')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSDK50e-sSu8",
        "colab_type": "text"
      },
      "source": [
        "## 1. Описательный анализ данных с привязкой к целевой переменной (toxic) и 2 другим дополнительным колонкам (как минимум 5 статистик на каждую группу) - 1.5 балл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVgTHTVQrG0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "d6c39789-7eab-4403-8aad-ebff80c0dedf"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             0\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4qLRnZtM_uP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07a9a710-e5c8-4795-f35c-7219c51995b4"
      },
      "source": [
        "len(data[data['toxic']==1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7DaPDPWNeS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "518d4c22-ec70-43c3-d383-a197336fa98d"
      },
      "source": [
        "len(data[data['toxic']==0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "202165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUub4b3eIkqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1598287c-e153-42d6-9346-c7ee26657451"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(223549, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykvhzn2CP_e2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_ascii(s):\n",
        "    return all(ord(c) < 128 for c in s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Z4bsJ_QDsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stops = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA0ESYCPMFrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['text_len'] = data['comment_text'].apply(len) #длина текста\n",
        "data['text_len_tokens'] = data['comment_text'].apply(lambda x: len(x.split())) #количество токенов\n",
        "data['number_of_caps'] = data['comment_text'].apply(lambda x: len([ch for ch in x if ch.isupper()])) #количество слов с заглавной буквы\n",
        "data['number_of_nonalphanum'] = data['comment_text'].apply(lambda x: len([ch for ch in x if not ch.isalnum()])) #количество  не буквенно-цифровых символов\n",
        "data['number_of_lows'] = data['comment_text'].apply(lambda x: len([ch for ch in x if ch.islower()])) #количество строчных букв\n",
        "data['number_of_digits'] = data['comment_text'].apply(lambda x: len([ch for ch in x if ch.isdigit()])) #количество цифр\n",
        "data['number_of_ascii'] = data['comment_text'].apply(lambda x: len([ch for ch in x if is_ascii(ch)])) #количество ascii символов\n",
        "data['number_of_nonascii'] = data['comment_text'].apply(lambda x: len([ch for ch in x if not is_ascii(ch)])) #количество non-ascii символов\n",
        "data['number_of_punctuation'] = data['comment_text'].apply(lambda x: len([ch for ch in x if ch in punctuation])) #количество знаков пунктуации\n",
        "data['number_of_stops'] = data['comment_text'].apply(lambda x: len([ch for ch in x if ch in stops])) #количество стоп-слов"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gQrAt86SL6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c2a3bfb8-897d-4a50-bda5-439ba52731b8"
      },
      "source": [
        "data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>text_len</th>\n",
              "      <th>text_len_tokens</th>\n",
              "      <th>number_of_caps</th>\n",
              "      <th>number_of_nonalphanum</th>\n",
              "      <th>number_of_lows</th>\n",
              "      <th>number_of_digits</th>\n",
              "      <th>number_of_ascii</th>\n",
              "      <th>number_of_nonascii</th>\n",
              "      <th>number_of_punctuation</th>\n",
              "      <th>number_of_stops</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>264</td>\n",
              "      <td>43</td>\n",
              "      <td>17</td>\n",
              "      <td>52</td>\n",
              "      <td>186</td>\n",
              "      <td>9</td>\n",
              "      <td>264</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>29</td>\n",
              "      <td>65</td>\n",
              "      <td>10</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>42</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>182</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... number_of_stops\n",
              "0  0000997932d777bf  ...              84\n",
              "1  000103f0d9cfb60f  ...              29\n",
              "2  000113f07ec002fd  ...              99\n",
              "\n",
              "[3 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is6Qp1Vy2-4C",
        "colab_type": "text"
      },
      "source": [
        "### Отдельные колонки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0AxvX6XXbeQ",
        "colab_type": "text"
      },
      "source": [
        "### Toxic/Non-toxic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pZtJvZgWNGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "a3ea7fe3-d49c-418e-8f53-a28e4990e521"
      },
      "source": [
        "data.groupby('toxic')['text_len', 'text_len_tokens', 'number_of_caps', 'number_of_nonalphanum', 'number_of_lows', 'number_of_digits', \n",
        "                      'number_of_ascii', 'number_of_nonascii', 'number_of_punctuation', 'number_of_stops'].agg(['mean'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>text_len</th>\n",
              "      <th>text_len_tokens</th>\n",
              "      <th>number_of_caps</th>\n",
              "      <th>number_of_nonalphanum</th>\n",
              "      <th>number_of_lows</th>\n",
              "      <th>number_of_digits</th>\n",
              "      <th>number_of_ascii</th>\n",
              "      <th>number_of_nonascii</th>\n",
              "      <th>number_of_punctuation</th>\n",
              "      <th>number_of_stops</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>402.691178</td>\n",
              "      <td>68.415161</td>\n",
              "      <td>14.484189</td>\n",
              "      <td>89.072456</td>\n",
              "      <td>294.922009</td>\n",
              "      <td>3.248698</td>\n",
              "      <td>400.972142</td>\n",
              "      <td>1.719036</td>\n",
              "      <td>16.974704</td>\n",
              "      <td>141.799609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>280.604097</td>\n",
              "      <td>48.573466</td>\n",
              "      <td>44.689675</td>\n",
              "      <td>65.266741</td>\n",
              "      <td>168.618921</td>\n",
              "      <td>1.995885</td>\n",
              "      <td>280.409512</td>\n",
              "      <td>0.194585</td>\n",
              "      <td>14.257202</td>\n",
              "      <td>80.432941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         text_len text_len_tokens  ... number_of_punctuation number_of_stops\n",
              "             mean            mean  ...                  mean            mean\n",
              "toxic                              ...                                      \n",
              "0      402.691178       68.415161  ...             16.974704      141.799609\n",
              "1      280.604097       48.573466  ...             14.257202       80.432941\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pt0HKP7XTWe",
        "colab_type": "text"
      },
      "source": [
        "1. Средняя длина нетоксичного комментария выше, чем у токсичного. \n",
        "2. Среднее количество слов у нетоксичных текстов также больше. \n",
        "3. Среднее количество используемых заглавных букв у токсичных сообщений в несколько рах выше, чем у нетоксичных.\n",
        "4. Среднее количество  не буквенно-цифровых символов в нетоксичных комментариях выше.\n",
        "5. Количество строчных букв в токсичных комментариях меньше, чем в нетоксичных.\n",
        "6. Цифр в нетоксичных комментариях также в среднем больше. \n",
        "7. Ascii-символов в нетоксичных комментариях больше.\n",
        "8. Не-ascii символов в целом по комментариям практически нет, но если они встречаются, то чаще в нетоксичных комментариях.\n",
        "9. Оба типа комментариев имеют практически одинаковое среднее количество знаков препинания. В нетоксичных комментариях их чуть больше. \n",
        "10. Используемых стоп-слов в нетоксичных комментариях гораздо больше, чем в токсичных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "992m3sndR2Yq",
        "colab_type": "text"
      },
      "source": [
        "### Severe_toxic/Non-severe_toxic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwwev4HSR0VL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "aac006eb-c550-41fe-9fbb-ba029b4dc9e8"
      },
      "source": [
        "data.groupby('severe_toxic')['text_len', 'text_len_tokens', 'number_of_caps', 'number_of_nonalphanum', 'number_of_lows', 'number_of_digits', \n",
        "                      'number_of_ascii', 'number_of_nonascii', 'number_of_punctuation', 'number_of_stops'].agg(['mean'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>text_len</th>\n",
              "      <th>text_len_tokens</th>\n",
              "      <th>number_of_caps</th>\n",
              "      <th>number_of_nonalphanum</th>\n",
              "      <th>number_of_lows</th>\n",
              "      <th>number_of_digits</th>\n",
              "      <th>number_of_ascii</th>\n",
              "      <th>number_of_nonascii</th>\n",
              "      <th>number_of_punctuation</th>\n",
              "      <th>number_of_stops</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>severe_toxic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>389.999386</td>\n",
              "      <td>66.358270</td>\n",
              "      <td>15.988131</td>\n",
              "      <td>86.500630</td>\n",
              "      <td>283.491852</td>\n",
              "      <td>3.136258</td>\n",
              "      <td>388.413228</td>\n",
              "      <td>1.586158</td>\n",
              "      <td>16.591014</td>\n",
              "      <td>136.307514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>505.456677</td>\n",
              "      <td>84.462793</td>\n",
              "      <td>173.841998</td>\n",
              "      <td>120.072375</td>\n",
              "      <td>209.248726</td>\n",
              "      <td>2.293068</td>\n",
              "      <td>505.345566</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>30.690112</td>\n",
              "      <td>93.232926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                text_len text_len_tokens  ... number_of_punctuation number_of_stops\n",
              "                    mean            mean  ...                  mean            mean\n",
              "severe_toxic                              ...                                      \n",
              "0             389.999386       66.358270  ...             16.591014      136.307514\n",
              "1             505.456677       84.462793  ...             30.690112       93.232926\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyI3mFJaSK1w",
        "colab_type": "text"
      },
      "source": [
        "1. Средняя длина сильно токсичных комментариев гораздо больше. \n",
        "2. Среднее количество слов в сильно токсичных комментариях выше.\n",
        "3. Количество заглавных букв в сильно токсичных текстах во много раз превышает количество в обычных комментариях.\n",
        "4. Среднее количество не буквенно-цифровых символов в токсичных комментариях выше.\n",
        "5. Строчных букв в обычных комментариях больше. \n",
        "6. В обоих типах комментариев цифр мало, но в обычных комментариях в среднем чуть больше.\n",
        "7. Ascii-символов больше в сильно токсичных комментариях.\n",
        "8. Не-ascii символы практически отсутствуют в обоих типах. В обычных чуть больше.\n",
        "9. Количество знаков пунктуации в среднем почти в 2 раза больше в токсичных комментариях.\n",
        "10. Количество стоп-слов в обычных комментариях в среднем больше. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8zOtYEPSMIy",
        "colab_type": "text"
      },
      "source": [
        "### Obscene/Non-obscene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWFqZkxUSMRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "2a4d663e-43cd-4f15-a674-2c1192936d93"
      },
      "source": [
        "data.groupby('obscene')['text_len', 'text_len_tokens', 'number_of_caps', 'number_of_nonalphanum', 'number_of_lows', 'number_of_digits', \n",
        "                      'number_of_ascii', 'number_of_nonascii', 'number_of_punctuation', 'number_of_stops'].agg(['mean'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>text_len</th>\n",
              "      <th>text_len_tokens</th>\n",
              "      <th>number_of_caps</th>\n",
              "      <th>number_of_nonalphanum</th>\n",
              "      <th>number_of_lows</th>\n",
              "      <th>number_of_digits</th>\n",
              "      <th>number_of_ascii</th>\n",
              "      <th>number_of_nonascii</th>\n",
              "      <th>number_of_punctuation</th>\n",
              "      <th>number_of_stops</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>obscene</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>397.332876</td>\n",
              "      <td>67.559707</td>\n",
              "      <td>15.299590</td>\n",
              "      <td>88.032052</td>\n",
              "      <td>289.883993</td>\n",
              "      <td>3.193029</td>\n",
              "      <td>395.678353</td>\n",
              "      <td>1.654523</td>\n",
              "      <td>16.850087</td>\n",
              "      <td>139.417163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>280.951730</td>\n",
              "      <td>48.362109</td>\n",
              "      <td>53.490033</td>\n",
              "      <td>65.257743</td>\n",
              "      <td>160.178748</td>\n",
              "      <td>2.011367</td>\n",
              "      <td>280.794481</td>\n",
              "      <td>0.157249</td>\n",
              "      <td>14.358072</td>\n",
              "      <td>75.193822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           text_len text_len_tokens  ... number_of_punctuation number_of_stops\n",
              "               mean            mean  ...                  mean            mean\n",
              "obscene                              ...                                      \n",
              "0        397.332876       67.559707  ...             16.850087      139.417163\n",
              "1        280.951730       48.362109  ...             14.358072       75.193822\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qID8tEdrSMh7",
        "colab_type": "text"
      },
      "source": [
        "1. Средняя длина грубых комментарией намного меньше, чем обычных.\n",
        "2. Количество слов в грубых текстах также меньше в среднем на 19.\n",
        "3. Заглавных букв в грубых комментариях во много раз больше.\n",
        "4. Среднее количество не буквенно-цифровых символов в грубых комментариях меньше.\n",
        "5. Негрубые тексты содержат гораздо больше строчных букв. \n",
        "6. Оба типа комментариев содержат мало цифр. В негрубых их в среднем на 1 больше.\n",
        "7. Количество ascii-символов практически полностью совпадает со средней длиной комментариев в обих типах.\n",
        "8. В негрубых в среднем встречается 1.6 не ascii-символов, что чуть больше, чем в грубых.\n",
        "9. Количество знаков пунктуации практически одинаковое, но в негрубых их на 2 больше, чем в грубых.\n",
        "10. В грубых комментариях используется меньше стоп-слов, чем в негрубых почти в 2 раза."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnJq1D5oSbqI",
        "colab_type": "text"
      },
      "source": [
        "### Threat/Non-threat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70T97KdAScIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "e2d30373-80e1-4386-a9dd-af1a5653690d"
      },
      "source": [
        "data.groupby('threat')['text_len', 'text_len_tokens', 'number_of_caps', 'number_of_nonalphanum', 'number_of_lows', 'number_of_digits', \n",
        "                      'number_of_ascii', 'number_of_nonascii', 'number_of_punctuation', 'number_of_stops'].agg(['mean'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>text_len</th>\n",
              "      <th>text_len_tokens</th>\n",
              "      <th>number_of_caps</th>\n",
              "      <th>number_of_nonalphanum</th>\n",
              "      <th>number_of_lows</th>\n",
              "      <th>number_of_digits</th>\n",
              "      <th>number_of_ascii</th>\n",
              "      <th>number_of_nonascii</th>\n",
              "      <th>number_of_punctuation</th>\n",
              "      <th>number_of_stops</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>threat</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>391.241807</td>\n",
              "      <td>66.547128</td>\n",
              "      <td>17.149430</td>\n",
              "      <td>86.796312</td>\n",
              "      <td>283.283766</td>\n",
              "      <td>3.134856</td>\n",
              "      <td>389.665157</td>\n",
              "      <td>1.576649</td>\n",
              "      <td>16.686637</td>\n",
              "      <td>136.141282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>316.910015</td>\n",
              "      <td>56.825835</td>\n",
              "      <td>89.866473</td>\n",
              "      <td>86.460087</td>\n",
              "      <td>139.383164</td>\n",
              "      <td>1.188679</td>\n",
              "      <td>316.448476</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>25.809869</td>\n",
              "      <td>67.416546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          text_len text_len_tokens  ... number_of_punctuation number_of_stops\n",
              "              mean            mean  ...                  mean            mean\n",
              "threat                              ...                                      \n",
              "0       391.241807       66.547128  ...             16.686637      136.141282\n",
              "1       316.910015       56.825835  ...             25.809869       67.416546\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs09jba7Scpb",
        "colab_type": "text"
      },
      "source": [
        "1. Длина текстов с угрозой меньше, чем текстов без угрозы.\n",
        "2. Количество слов в текстах без угрозы на 10 больше. \n",
        "3. Количество заглавных букв в текстах с угрозой во много раз больше, чем в текстах без.\n",
        "4. Среднее количество не буквенно-цифровых символов одинаково.\n",
        "5. Количество строчных букв в текстах без угрозы больше, чем в 2 раза.\n",
        "6. Количество цифр в обоих типах мало, но в текстах без угрозы их в среднем чуть больше.\n",
        "7. Количество ascii-символов практически полностью совпадает со средней длиной комментариев в обих типах.\n",
        "8. Не ascii-символы практически отсутствуют в обоих типах. В текстах без угрозы в среднем их 1.6.\n",
        "9. Знаки пунктуации присутствуют в обоих типах комментариев и их количество почти одинаковое.\n",
        "10. Количество использованных стоп-слов больше в текстах без угрозы в 2 раза. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCL5bm8hSrBd",
        "colab_type": "text"
      },
      "source": [
        "### Insult/Non-insult"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IHhN3H8SrMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "e8f232c2-2c2b-47fe-ef12-159ab58e8495"
      },
      "source": [
        "data.groupby('insult')['text_len', 'text_len_tokens', 'number_of_caps', 'number_of_nonalphanum', 'number_of_lows', 'number_of_digits', \n",
        "                      'number_of_ascii', 'number_of_nonascii', 'number_of_punctuation', 'number_of_stops'].agg(['mean'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>text_len</th>\n",
              "      <th>text_len_tokens</th>\n",
              "      <th>number_of_caps</th>\n",
              "      <th>number_of_nonalphanum</th>\n",
              "      <th>number_of_lows</th>\n",
              "      <th>number_of_digits</th>\n",
              "      <th>number_of_ascii</th>\n",
              "      <th>number_of_nonascii</th>\n",
              "      <th>number_of_punctuation</th>\n",
              "      <th>number_of_stops</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insult</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>397.340234</td>\n",
              "      <td>67.544536</td>\n",
              "      <td>15.573931</td>\n",
              "      <td>88.053302</td>\n",
              "      <td>289.597522</td>\n",
              "      <td>3.194615</td>\n",
              "      <td>395.690669</td>\n",
              "      <td>1.649565</td>\n",
              "      <td>16.879710</td>\n",
              "      <td>139.233245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>272.206476</td>\n",
              "      <td>47.227176</td>\n",
              "      <td>51.163393</td>\n",
              "      <td>63.174452</td>\n",
              "      <td>155.965057</td>\n",
              "      <td>1.894197</td>\n",
              "      <td>272.066879</td>\n",
              "      <td>0.139597</td>\n",
              "      <td>13.617569</td>\n",
              "      <td>73.897381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          text_len text_len_tokens  ... number_of_punctuation number_of_stops\n",
              "              mean            mean  ...                  mean            mean\n",
              "insult                              ...                                      \n",
              "0       397.340234       67.544536  ...             16.879710      139.233245\n",
              "1       272.206476       47.227176  ...             13.617569       73.897381\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_PX3EINSrb0",
        "colab_type": "text"
      },
      "source": [
        "1. Средняя длина комментария с оскорблением меньше, чем обычный комментарий.\n",
        "2. В обычном комментарии в среднем на 20 слов больше, чем в тексте с оскорблением.\n",
        "3. Количество заглавных букв в тексте с оскорблением в несколько раз больше.\n",
        "4. Среднее количество не буквенно-цифровых символов в обычных комментариях больше, чем в оскорбительных.\n",
        "5. Количество строчных букв почти в 2 раза больше в комментариях без оскорбления.\n",
        "6. Количество цифр в обоих типах мало, но в текстах без оскорбления их в среднем чуть больше.\n",
        "7. Количество ascii-символов практически полностью совпадает со средней длиной комментариев в обих типах.\n",
        "8. Не ascii-символы практически отсутствуют в обоих типах. В текстах без оскорбления в среднем их 1.6.\n",
        "9. Знаки пунктуации присутствуют в обоих типах комментариев и их количество почти одинаковое.\n",
        "10. Количество использованных стоп-слов больше в текстах без оскорбления в 2 раза."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tThoJsZaTAku",
        "colab_type": "text"
      },
      "source": [
        "### Identity_hate/Non-identity_hate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV6Yml-rTA1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "8e6708f7-7b8d-4d18-92b1-5a0228adfc25"
      },
      "source": [
        "data.groupby('identity_hate')['text_len', 'text_len_tokens', 'number_of_caps', 'number_of_nonalphanum', 'number_of_lows', 'number_of_digits', \n",
        "                      'number_of_ascii', 'number_of_nonascii', 'number_of_punctuation', 'number_of_stops'].agg(['mean'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>text_len</th>\n",
              "      <th>text_len_tokens</th>\n",
              "      <th>number_of_caps</th>\n",
              "      <th>number_of_nonalphanum</th>\n",
              "      <th>number_of_lows</th>\n",
              "      <th>number_of_digits</th>\n",
              "      <th>number_of_ascii</th>\n",
              "      <th>number_of_nonascii</th>\n",
              "      <th>number_of_punctuation</th>\n",
              "      <th>number_of_stops</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>identity_hate</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>391.744793</td>\n",
              "      <td>66.651428</td>\n",
              "      <td>16.774599</td>\n",
              "      <td>86.960259</td>\n",
              "      <td>283.989184</td>\n",
              "      <td>3.137812</td>\n",
              "      <td>390.158234</td>\n",
              "      <td>1.586559</td>\n",
              "      <td>16.740187</td>\n",
              "      <td>136.492779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>314.438829</td>\n",
              "      <td>52.473784</td>\n",
              "      <td>80.022201</td>\n",
              "      <td>69.538498</td>\n",
              "      <td>162.665092</td>\n",
              "      <td>2.192253</td>\n",
              "      <td>314.261691</td>\n",
              "      <td>0.177137</td>\n",
              "      <td>14.054795</td>\n",
              "      <td>77.008503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 text_len text_len_tokens  ... number_of_punctuation number_of_stops\n",
              "                     mean            mean  ...                  mean            mean\n",
              "identity_hate                              ...                                      \n",
              "0              391.744793       66.651428  ...             16.740187      136.492779\n",
              "1              314.438829       52.473784  ...             14.054795       77.008503\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B141c7MdTBCD",
        "colab_type": "text"
      },
      "source": [
        "1. Средняя длина комментария без ненависти личности больше на примерно 75 слов.\n",
        "2. Обычные комментарии в среднем имеют больше слов.\n",
        "3. Количество заглавных букв в тексте с ненавистью личности в несколько раз больше.\n",
        "4. Среднее количество не буквенно-цифровых символов в обычных комментариях больше. \n",
        "5. Количество строчных букв почти в 2 раза больше в комментариях без ненависти.\n",
        "6. Количество цифр в обоих типах мало, но в текстах без оскорбления их в среднем чуть больше.\n",
        "7. Количество ascii-символов практически полностью совпадает со средней длиной комментариев в обих типах.\n",
        "8. Не ascii-символы практически отсутствуют в обоих типах. В текстах без ненависти в среднем их 1.58.\n",
        "9. Знаки пунктуации присутствуют в обоих типах комментариев и их количество почти одинаковое.\n",
        "10. Количество использованных стоп-слов больше в текстах без ненависти меньше, чем в 2 раза."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOkEwsDqWqMO",
        "colab_type": "text"
      },
      "source": [
        "### Привязка к другим колонкам"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Eb18_63Zxj",
        "colab_type": "text"
      },
      "source": [
        "### Toxic/Insult"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS5n-UcsW1Ol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "58584c9d-8a44-4704-a83a-b929746cdc3c"
      },
      "source": [
        "data.groupby(['toxic', 'insult'])['text_len', 'text_len_tokens', 'number_of_caps', 'number_of_nonalphanum', 'number_of_lows', 'number_of_digits', \n",
        "                      'number_of_ascii', 'number_of_nonascii', 'number_of_punctuation', 'number_of_stops'].agg(['mean'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text_len</th>\n",
              "      <th>text_len_tokens</th>\n",
              "      <th>number_of_caps</th>\n",
              "      <th>number_of_nonalphanum</th>\n",
              "      <th>number_of_lows</th>\n",
              "      <th>number_of_digits</th>\n",
              "      <th>number_of_ascii</th>\n",
              "      <th>number_of_nonascii</th>\n",
              "      <th>number_of_punctuation</th>\n",
              "      <th>number_of_stops</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th>insult</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>402.813001</td>\n",
              "      <td>68.433497</td>\n",
              "      <td>14.441753</td>\n",
              "      <td>89.097684</td>\n",
              "      <td>295.067930</td>\n",
              "      <td>3.239016</td>\n",
              "      <td>401.089875</td>\n",
              "      <td>1.723127</td>\n",
              "      <td>16.978293</td>\n",
              "      <td>141.864081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>362.961165</td>\n",
              "      <td>62.435275</td>\n",
              "      <td>28.323625</td>\n",
              "      <td>80.844660</td>\n",
              "      <td>247.333333</td>\n",
              "      <td>6.406149</td>\n",
              "      <td>362.576052</td>\n",
              "      <td>0.385113</td>\n",
              "      <td>15.804207</td>\n",
              "      <td>120.773463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>294.234997</td>\n",
              "      <td>50.796784</td>\n",
              "      <td>36.903814</td>\n",
              "      <td>68.377454</td>\n",
              "      <td>186.536736</td>\n",
              "      <td>2.358104</td>\n",
              "      <td>293.971303</td>\n",
              "      <td>0.263694</td>\n",
              "      <td>15.022434</td>\n",
              "      <td>89.669097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>266.957889</td>\n",
              "      <td>46.347651</td>\n",
              "      <td>52.484278</td>\n",
              "      <td>62.152536</td>\n",
              "      <td>150.680984</td>\n",
              "      <td>1.633258</td>\n",
              "      <td>266.832491</td>\n",
              "      <td>0.125398</td>\n",
              "      <td>13.491110</td>\n",
              "      <td>71.186412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                text_len text_len_tokens  ... number_of_punctuation number_of_stops\n",
              "                    mean            mean  ...                  mean            mean\n",
              "toxic insult                              ...                                      \n",
              "0     0       402.813001       68.433497  ...             16.978293      141.864081\n",
              "      1       362.961165       62.435275  ...             15.804207      120.773463\n",
              "1     0       294.234997       50.796784  ...             15.022434       89.669097\n",
              "      1       266.957889       46.347651  ...             13.491110       71.186412\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nMJL4OP3doQ",
        "colab_type": "text"
      },
      "source": [
        "1. Non-toxic/non-insult имеют самую большую среднюю длину. В non-toxic/insult комментариях длина текста больше, чем просто в toxic/non-insult. Toxic/insult в свою очередь имеют самые короткие тексты.\n",
        "2. Non-toxic/non-insult имеют самое большое количество слов. В insult комментариях слов в среднем на 12 больше, чем просто в toxic/non-insult. Toxic/insult в свою очередь имеют меньше всего слов.\n",
        "3. Заглавных букв больше всего в комментариях имеющие обе метки toxic/insult. Меньше всего в обычных комментариях без меток. Токсичные комментарии имеют больше заглавных букв, чем оскорбительные.\n",
        "4. Среднее количество не буквенно-цифровых символов в обычных комментариях больше. Toxic/non-insult комментарии имеют меньше данных символов, чем non-toxic/insult. \n",
        "5. Количество строчных букв больше всего в комментариях без меток. Меньше всего строчных букв в комментариях с обеими метками toxic и insult. \n",
        "6. В комментариях всех типов используется мало цифр. Больше всего в текстах non-toxic/insult, меньше всего в toxic/insult. \n",
        "7. Количество ascii-символов практически полностью совпадает со средней длиной комментариев во всех типах.\n",
        "8. Не ascii-символы практически отсутствуют в данных типах.\n",
        "9. Знаков пунктуации больше всего в обычных комментариях. В комментариях toxic/insult их наименьшее количество.\n",
        "10. Больше всего стоп-слов в обычных комментариях. Меньше всего в toxic/insult. В toxic/non-insult их меньше, чем в non-toxic/insult."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdSSDJek3fZK",
        "colab_type": "text"
      },
      "source": [
        "### Toxic/Obscene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIN5M3Pp3ljX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "179c44e6-fb0d-4007-a44f-93443323abb9"
      },
      "source": [
        "data.groupby(['toxic', 'obscene'])['text_len', 'text_len_tokens', 'number_of_caps', 'number_of_nonalphanum', 'number_of_lows', 'number_of_digits', \n",
        "                      'number_of_ascii', 'number_of_nonascii', 'number_of_punctuation', 'number_of_stops'].agg(['mean'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text_len</th>\n",
              "      <th>text_len_tokens</th>\n",
              "      <th>number_of_caps</th>\n",
              "      <th>number_of_nonalphanum</th>\n",
              "      <th>number_of_lows</th>\n",
              "      <th>number_of_digits</th>\n",
              "      <th>number_of_ascii</th>\n",
              "      <th>number_of_nonascii</th>\n",
              "      <th>number_of_punctuation</th>\n",
              "      <th>number_of_stops</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>402.480948</td>\n",
              "      <td>68.373545</td>\n",
              "      <td>14.440551</td>\n",
              "      <td>89.018316</td>\n",
              "      <td>294.816601</td>\n",
              "      <td>3.239035</td>\n",
              "      <td>400.758162</td>\n",
              "      <td>1.722786</td>\n",
              "      <td>16.961355</td>\n",
              "      <td>141.744579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>474.761905</td>\n",
              "      <td>82.681973</td>\n",
              "      <td>29.443878</td>\n",
              "      <td>107.632653</td>\n",
              "      <td>331.057823</td>\n",
              "      <td>6.561224</td>\n",
              "      <td>474.328231</td>\n",
              "      <td>0.433673</td>\n",
              "      <td>21.551020</td>\n",
              "      <td>160.664966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>291.786412</td>\n",
              "      <td>50.874288</td>\n",
              "      <td>32.911717</td>\n",
              "      <td>67.811534</td>\n",
              "      <td>188.754984</td>\n",
              "      <td>2.249797</td>\n",
              "      <td>291.531428</td>\n",
              "      <td>0.254984</td>\n",
              "      <td>14.568857</td>\n",
              "      <td>91.700163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>271.086738</td>\n",
              "      <td>46.615218</td>\n",
              "      <td>54.713989</td>\n",
              "      <td>63.100848</td>\n",
              "      <td>151.480956</td>\n",
              "      <td>1.779778</td>\n",
              "      <td>270.943560</td>\n",
              "      <td>0.143179</td>\n",
              "      <td>13.991949</td>\n",
              "      <td>70.843317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 text_len text_len_tokens  ... number_of_punctuation number_of_stops\n",
              "                     mean            mean  ...                  mean            mean\n",
              "toxic obscene                              ...                                      \n",
              "0     0        402.480948       68.373545  ...             16.961355      141.744579\n",
              "      1        474.761905       82.681973  ...             21.551020      160.664966\n",
              "1     0        291.786412       50.874288  ...             14.568857       91.700163\n",
              "      1        271.086738       46.615218  ...             13.991949       70.843317\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTmOT5MU3pVA",
        "colab_type": "text"
      },
      "source": [
        "1. Non-toxic/obscene комментарии являются самыми длинными. Toxic/obscene имеют самую маленькую длину.\n",
        "2. Больше всего слов в грубых комментариях non-toxic/obscene. Меньше всего в toxic/obscene вместе.\n",
        "3. Наибольшее количество заглавных букв наблюдается в toxic/obscene комментариях. В нормальных комментариях их меньше всего. Грубые и токсичные комментарии отдельно имеют примерно одинаковое количество заглавных букв.\n",
        "4. Среднее количество не буквенно-цифровых символов в грубых комментариях больше. Toxic/obscene комментарии имеют меньше всего данных символов.\n",
        "5. Больше всего строчных букв в грубых комментариях non-toxic/obscene. Toxic/obscene имеют меньше всего данных букв.\n",
        "6. В комментариях всех типов используется мало цифр. Больше всего в текстах obscene, меньше всего в toxic/obscene.\n",
        "7. Количество ascii-символов практически полностью совпадает со средней длиной комментариев в обих типах.\n",
        "8. Не ascii-символы практически отсутствуют в данных типах.\n",
        "9. Больше всего знаков пунктуации в грубых комментариях non-toxic/obscene.\n",
        "10. Non-toxic/obscene грубые комментарии имеют больше всего стоп-слов. Меньше всего в toxic/obscene."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0WOh5Ky3rHv",
        "colab_type": "text"
      },
      "source": [
        "### Toxic/Threat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yADbYMS3qfI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "341482fb-c778-4a63-901d-88c94ff48ea6"
      },
      "source": [
        "data.groupby(['toxic', 'threat'])['text_len', 'text_len_tokens', 'number_of_caps', 'number_of_nonalphanum', 'number_of_lows', 'number_of_digits', \n",
        "                      'number_of_ascii', 'number_of_nonascii', 'number_of_punctuation', 'number_of_stops'].agg(['mean'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text_len</th>\n",
              "      <th>text_len_tokens</th>\n",
              "      <th>number_of_caps</th>\n",
              "      <th>number_of_nonalphanum</th>\n",
              "      <th>number_of_lows</th>\n",
              "      <th>number_of_digits</th>\n",
              "      <th>number_of_ascii</th>\n",
              "      <th>number_of_nonascii</th>\n",
              "      <th>number_of_punctuation</th>\n",
              "      <th>number_of_stops</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th>threat</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>402.693648</td>\n",
              "      <td>68.415233</td>\n",
              "      <td>14.473087</td>\n",
              "      <td>89.073487</td>\n",
              "      <td>294.934681</td>\n",
              "      <td>3.248400</td>\n",
              "      <td>400.974492</td>\n",
              "      <td>1.719156</td>\n",
              "      <td>16.975268</td>\n",
              "      <td>141.805764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>388.428571</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>78.600000</td>\n",
              "      <td>83.114286</td>\n",
              "      <td>221.742857</td>\n",
              "      <td>4.971429</td>\n",
              "      <td>387.400000</td>\n",
              "      <td>1.028571</td>\n",
              "      <td>13.714286</td>\n",
              "      <td>106.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>279.579450</td>\n",
              "      <td>48.331983</td>\n",
              "      <td>43.245393</td>\n",
              "      <td>64.592475</td>\n",
              "      <td>169.680318</td>\n",
              "      <td>2.027738</td>\n",
              "      <td>279.392330</td>\n",
              "      <td>0.187120</td>\n",
              "      <td>13.872311</td>\n",
              "      <td>80.909165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>313.082569</td>\n",
              "      <td>56.227829</td>\n",
              "      <td>90.469419</td>\n",
              "      <td>86.639144</td>\n",
              "      <td>134.975535</td>\n",
              "      <td>0.986239</td>\n",
              "      <td>312.651376</td>\n",
              "      <td>0.431193</td>\n",
              "      <td>26.457187</td>\n",
              "      <td>65.337920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                text_len text_len_tokens  ... number_of_punctuation number_of_stops\n",
              "                    mean            mean  ...                  mean            mean\n",
              "toxic threat                              ...                                      \n",
              "0     0       402.693648       68.415233  ...             16.975268      141.805764\n",
              "      1       388.428571       68.000000  ...             13.714286      106.257143\n",
              "1     0       279.579450       48.331983  ...             13.872311       80.909165\n",
              "      1       313.082569       56.227829  ...             26.457187       65.337920\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYL5Ivg33yzf",
        "colab_type": "text"
      },
      "source": [
        "1. Обычные комментарии самые длинные. Самыми короткими являются комментарии типа toxic/non-threat. В non-toxic/threat также наблюдается большая средняя длина. \n",
        "2. Обычные комментарии и non-toxic/threat имеют одинаковое среднее количество слов. Меньше всего слов в toxic/non-threat комментариях. \n",
        "3. Заглавных букв больше всего в toxic/threat комментариях. Меньше всего в обычных. Тексты с угрозой имеют больше заглавных букв, чем токсичные.\n",
        "4. Среднее количество не буквенно-цифровых символов незначительно отличается. В toxic/non-threat комментариях их меньше всего. В остальных типах их примерно одинаково.\n",
        "5. Больше всего строчных букв в обычных комментариях. Меньше всего в toxic/threat. Non-toxic/threat имеют больше строчных букв, чем toxic/non threat. \n",
        "6. В комментариях всех типов используется мало цифр. Больше всего в текстах threat, меньше всего в toxic/threat.\n",
        "7. Количество ascii-символов практически полностью совпадает со средней длиной комментариев в обих типах.\n",
        "8. Не ascii-символы практически отсутствуют в данных типах.\n",
        "9. Больше всего знаков пунктуации в текстах toxic/threat. В toxic/non-threat и non-toxic/threat их примерно одинаково.\n",
        "10. Наибольшее количество стоп-слов наблюдается в текстах комментариев типа non-toxic/non-threat. Меньше всего в toxic/threat. В комментариях non-toxic/threat их больше, чем в toxic/non-threat. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9TVfOYR0Xs5",
        "colab_type": "text"
      },
      "source": [
        "## 2. Бейзлайн модель из sklearn (векторайзер + модель) с отбором признаков (через l1 регуляризацию, на глаз через анализ важных параметров или через permutation importance) - 2 балл"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV4nfdYA96F7",
        "colab_type": "text"
      },
      "source": [
        "### Бейзлайн"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2gwR4gt3zx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data['comment_text']\n",
        "y = data['toxic']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPvLM4wmyJo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMb6eTyd4vyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vect = CountVectorizer()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCHukUg84zql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91e36246-f122-45aa-ce39-e74716bfe611"
      },
      "source": [
        "X_train = count_vect.fit_transform(X_train)\n",
        "X_train.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149777, 207901)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yajKEe705QDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "145bd9ab-f573-408e-dbf7-cebed3eff1b6"
      },
      "source": [
        "X_test = count_vect.transform(X_test)\n",
        "X_test.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(73772, 207901)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmsx7fQf5tKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = SGDClassifier().fit(X_train, y_train)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUMX-Hv26p97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTz_FEH09KR4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "03329a30-83af-4fd0-e612-e4adfb3b1020"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     66765\n",
            "           1       0.82      0.60      0.69      7007\n",
            "\n",
            "    accuracy                           0.95     73772\n",
            "   macro avg       0.89      0.79      0.83     73772\n",
            "weighted avg       0.95      0.95      0.95     73772\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk03LEJ19yRR",
        "colab_type": "text"
      },
      "source": [
        "### Top features Eli5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH-cdUPXDo-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "52feb30b-9b27-4b8b-c4a0-d41c7f09fb88"
      },
      "source": [
        "eli5.formatters.as_dataframe.explain_weights_df(clf)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>feature</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>x70089</td>\n",
              "      <td>2.211976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>x84835</td>\n",
              "      <td>2.087682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>x64497</td>\n",
              "      <td>2.057759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>x20704</td>\n",
              "      <td>1.988707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>x70128</td>\n",
              "      <td>1.869016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69604</th>\n",
              "      <td>1</td>\n",
              "      <td>x69507</td>\n",
              "      <td>-1.397159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69605</th>\n",
              "      <td>1</td>\n",
              "      <td>x103580</td>\n",
              "      <td>-1.583600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69606</th>\n",
              "      <td>1</td>\n",
              "      <td>x166952</td>\n",
              "      <td>-1.627333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69607</th>\n",
              "      <td>1</td>\n",
              "      <td>x67193</td>\n",
              "      <td>-1.811472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69608</th>\n",
              "      <td>1</td>\n",
              "      <td>x122363</td>\n",
              "      <td>-2.232692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69609 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       target  feature    weight\n",
              "0           1   x70089  2.211976\n",
              "1           1   x84835  2.087682\n",
              "2           1   x64497  2.057759\n",
              "3           1   x20704  1.988707\n",
              "4           1   x70128  1.869016\n",
              "...       ...      ...       ...\n",
              "69604       1   x69507 -1.397159\n",
              "69605       1  x103580 -1.583600\n",
              "69606       1  x166952 -1.627333\n",
              "69607       1   x67193 -1.811472\n",
              "69608       1  x122363 -2.232692\n",
              "\n",
              "[69609 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o7n1LI95Qsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_features(model, n):\n",
        "  index_to_word = {v:k for k,v in count_vect.vocabulary_.items()}\n",
        "  data = eli5.formatters.as_dataframe.explain_weights_df(model)\n",
        "  \n",
        "  class1 = data[data['target']==1]\n",
        "  \n",
        "  print('\\n', n, 'самых значимых признаков класса (toxic):')\n",
        "  for element in class1.feature[:n]:\n",
        "    feature = element.strip('x')\n",
        "    print(index_to_word[int(feature)], element)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tDYpjAa5q0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "489b5925-be41-42ad-c6cb-26b4af77964d"
      },
      "source": [
        "analyze_features(clf, 30)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 30 самых значимых признаков класса (toxic):\n",
            "fuck x70089\n",
            "idiot x84835\n",
            "faggot x64497\n",
            "asshole x20704\n",
            "fucking x70128\n",
            "idiots x84845\n",
            "suck x164233\n",
            "shit x154929\n",
            "fucked x70099\n",
            "bitch x28022\n",
            "stupid x163563\n",
            "bark x24314\n",
            "moron x114373\n",
            "cunt x46526\n",
            "ass x20589\n",
            "bastard x24691\n",
            "nigger x119855\n",
            "sucks x164261\n",
            "motherfucker x114630\n",
            "bullshit x32375\n",
            "penis x129840\n",
            "dicks x51942\n",
            "jerk x91987\n",
            "cock x40275\n",
            "dumbass x56450\n",
            "fuckin x70126\n",
            "fag x64461\n",
            "france x69133\n",
            "nigga x119839\n",
            "niggers x119867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpV-lJ9JWaRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2703d65-a6a4-4eb8-f96c-f4457c678c3c"
      },
      "source": [
        "sum(sum(clf.coef_ != 0))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69608"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfe0px_MVwwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_features = [int(i[1:]) for i in eli5.formatters.as_dataframe.explain_weights_df(clf).feature if 'BIAS' not in i]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpv-y9HWV6qO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22818e63-be23-4eb1-cdb9-045841d14ef0"
      },
      "source": [
        "len(top_features)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69608"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9-Hk2SDrCnq",
        "colab_type": "text"
      },
      "source": [
        "### Top features without BIAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsyTu9DvrHct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_eli5 = X_train[:,top_features]\n",
        "X_test_eli5 = X_test[:,top_features]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N06mhC_RrWWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eli5_model = SGDClassifier().fit(X_train_eli5, y_train)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFh6HxQerZhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = eli5_model.predict(X_test_eli5)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVx9XtiNre-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "14aca008-6d3e-4038-d8b7-c9988d1adb86"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     66765\n",
            "           1       0.81      0.60      0.69      7007\n",
            "\n",
            "    accuracy                           0.95     73772\n",
            "   macro avg       0.89      0.79      0.83     73772\n",
            "weighted avg       0.95      0.95      0.95     73772\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q1kXebssCRR",
        "colab_type": "text"
      },
      "source": [
        "По сравнению с бейзлайном precision метки 1 снизился до 0.81. Все остальные метрики не изминились."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD0wGAwR8Ghj",
        "colab_type": "text"
      },
      "source": [
        "### Top 1000 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd-Js2db6_0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top1000_features = top_features[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo9TKkaMWl4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_eli5 = X_train[:,top1000_features]\n",
        "X_test_eli5 = X_test[:,top1000_features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImLbARvbWocs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eli5_model = SGDClassifier().fit(X_train_eli5, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGe-IELmXQlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = eli5_model.predict(X_test_eli5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc4VYCg-XuVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "2948fb9f-ddb2-4be6-afc9-86c10302c0ff"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96     66765\n",
            "           1       0.70      0.49      0.58      7007\n",
            "\n",
            "    accuracy                           0.93     73772\n",
            "   macro avg       0.82      0.74      0.77     73772\n",
            "weighted avg       0.92      0.93      0.93     73772\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5WhdAIO-eul",
        "colab_type": "text"
      },
      "source": [
        "По сравнению с бейзлайном precision метки 1 снизился до 0.70, recall меток 0 и 1 снизился до 0.98 и 0.49, f1-score снизился до 0.93."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFj_fzeK8STC",
        "colab_type": "text"
      },
      "source": [
        "### Top 10000 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr673l5u8WFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top10000_features = top_features[:10000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khaRoE768Ykf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_eli5 = X_train[:,top10000_features]\n",
        "X_test_eli5 = X_test[:,top10000_features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8Igm0Gx8Yvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eli5_model = SGDClassifier().fit(X_train_eli5, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGqxO9Mk8Y5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = eli5_model.predict(X_test_eli5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlMfwmv-8cjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "c8c06ef5-91db-4f12-a185-9f0f938946df"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97     66765\n",
            "           1       0.78      0.55      0.65      7007\n",
            "\n",
            "    accuracy                           0.94     73772\n",
            "   macro avg       0.87      0.77      0.81     73772\n",
            "weighted avg       0.94      0.94      0.94     73772\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdtl3O50_y2e",
        "colab_type": "text"
      },
      "source": [
        "По сравнению с бейзлайном precision меток 0 и 1 снизился до 0.95 0.78, recall меток 0 и 1 снизился до 0.98 и 0.55, f1-score снизился до 0.94. Результаты по сравнению с top 1000 features улучшились. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx7s7rgJ8mE7",
        "colab_type": "text"
      },
      "source": [
        "### Top 30000 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qMz0IL28qQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top30000_features = top_features[:30000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u54tRADf8q0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_eli5 = X_train[:,top30000_features]\n",
        "X_test_eli5 = X_test[:,top30000_features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN-_iBV58q91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eli5_model = SGDClassifier().fit(X_train_eli5, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CogYipJm8rIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = eli5_model.predict(X_test_eli5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niJiAosI8rVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "785444bb-664f-4abd-a496-d05f1d0fbb18"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     66765\n",
            "           1       0.81      0.54      0.65      7007\n",
            "\n",
            "    accuracy                           0.94     73772\n",
            "   macro avg       0.88      0.76      0.81     73772\n",
            "weighted avg       0.94      0.94      0.94     73772\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iFfNL2epzT1",
        "colab_type": "text"
      },
      "source": [
        "По сравнению с бейзлайном precision меток 0 и 1 снизился до 0.95 и 0.81, recall метки 1 снизился до 0.54, f1-score снизился до 0.94. Результаты по сравнению с top 10000 features улучшились."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqS3w13T8_dS",
        "colab_type": "text"
      },
      "source": [
        "### Top 50000 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAaj6tMI9Gt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top50000_features = top_features[:50000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B6o6uue9G2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_eli5 = X_train[:,top50000_features]\n",
        "X_test_eli5 = X_test[:,top50000_features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLfHvc0s9HBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eli5_model = SGDClassifier().fit(X_train_eli5, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlBj7NG69G94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = eli5_model.predict(X_test_eli5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfjrONQ49G6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "bb6d8455-13d3-4b83-81f0-a3de51361bc1"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     66765\n",
            "           1       0.82      0.54      0.65      7007\n",
            "\n",
            "    accuracy                           0.95     73772\n",
            "   macro avg       0.89      0.77      0.81     73772\n",
            "weighted avg       0.94      0.95      0.94     73772\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_lRQVVlqbNB",
        "colab_type": "text"
      },
      "source": [
        "По сравнению с бейзлайном precision меток 0 и 1 снизился до 0.95 0.82, recall метки 1 снизился до 0.54. Результаты по сравнению с top 30000 features улучшились."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRnXWT4Y0zFQ",
        "colab_type": "text"
      },
      "source": [
        "## 3. Ансамбль из моделей в sklearn (ансамблевые модели типа randomforest не считаются). Нужно минимум 5 разных моделей - 2 балла"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg_4oDPjVQ6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "data_majority = data[data.toxic==0]\n",
        "data_minority = data[data.toxic==1]\n",
        "length = len(data_minority)\n",
        "\n",
        "data_majority_downsampled = resample(data_majority, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=length,     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        "\n",
        "data_downsampled = pd.concat([data_majority_downsampled, data_minority])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-hMT9ylW-3B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "983b898b-5e5b-4d1b-d82a-f338641e281b"
      },
      "source": [
        "data_downsampled.toxic.value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    21384\n",
              "0    21384\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKf6Qw7VX-jq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data_downsampled['comment_text']\n",
        "y = data_downsampled['toxic']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFeZJptiYRvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57J7m_IZQwH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = SGDClassifier(loss = 'hinge')\n",
        "clf2 = GaussianNB()\n",
        "clf3 = LogisticRegression()\n",
        "clf4 = SVC()\n",
        "clf5 = XGBClassifier()\n",
        "\n",
        "eclf = VotingClassifier(estimators=[\n",
        "        ('SGD', clf1), ('GaussianNB', clf2), ('LogReg', clf3),  ('SVC', clf4),  ('XGB', clf5)], voting='soft')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dtvN7UXY1B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voting = Pipeline([\n",
        "    ('vect', CountVectorizer(analyzer='word', max_features=200)),\n",
        "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "    ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
        "    ('clf', eclf),\n",
        "    ])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWRuK7IVFIrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voting = voting.fit(X_train, y_train)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWCocf56aks3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62a89e80-74c6-4d75-e799-ad136cb33450"
      },
      "source": [
        "predictions = voting.predict(X_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-ebaabd98e045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'soft'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mmaj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 'hard' voting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;34m\"\"\"Predict class probabilities for X in 'soft' voting.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         avg = np.average(self._collect_probas(X), axis=0,\n\u001b[0m\u001b[1;32m    260\u001b[0m                          weights=self._weights_not_none)\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m_collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0mhttp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mjmlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medu\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpapers\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvolume2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mzhang02c\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mzhang02c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \"\"\"\n\u001b[0;32m--> 995\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"modified_huber\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             raise AttributeError(\"probability estimates are not available for\"\n\u001b[0;32m--> 956\u001b[0;31m                                  \" loss=%r\" % self.loss)\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: probability estimates are not available for loss='hinge'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6fptGFYamtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}